{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>MooreRating_x</th>\n",
       "      <th>MooreRating_y</th>\n",
       "      <th>Seed_x</th>\n",
       "      <th>3ptRate_x</th>\n",
       "      <th>Ast%_x</th>\n",
       "      <th>FT%_x</th>\n",
       "      <th>OppFT%_x</th>\n",
       "      <th>Opp3ptRate_x</th>\n",
       "      <th>OppAst%_x</th>\n",
       "      <th>...</th>\n",
       "      <th>xOffyOffFTRateDiff</th>\n",
       "      <th>AbsxOffyDefAstDiff</th>\n",
       "      <th>AbsyOffxDefAstDiff</th>\n",
       "      <th>xOffyDefAstAvg</th>\n",
       "      <th>yOffxDefAstAvg</th>\n",
       "      <th>xOffyOffAstDiff</th>\n",
       "      <th>TotalPossVarSum</th>\n",
       "      <th>GameScoreVarSum</th>\n",
       "      <th>AvgTotalPoss</th>\n",
       "      <th>MooreNaiveUpsetProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>91.81</td>\n",
       "      <td>78.17</td>\n",
       "      <td>4</td>\n",
       "      <td>0.153633</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.687204</td>\n",
       "      <td>0.318363</td>\n",
       "      <td>0.449704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103332</td>\n",
       "      <td>0.046362</td>\n",
       "      <td>0.116533</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.507970</td>\n",
       "      <td>0.031723</td>\n",
       "      <td>323.329209</td>\n",
       "      <td>249.795260</td>\n",
       "      <td>142.390152</td>\n",
       "      <td>0.111138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>91.81</td>\n",
       "      <td>82.29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.153633</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.687204</td>\n",
       "      <td>0.318363</td>\n",
       "      <td>0.449704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137651</td>\n",
       "      <td>0.109423</td>\n",
       "      <td>0.216030</td>\n",
       "      <td>0.617586</td>\n",
       "      <td>0.557719</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>498.758776</td>\n",
       "      <td>240.489802</td>\n",
       "      <td>139.451000</td>\n",
       "      <td>0.192651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>95.45</td>\n",
       "      <td>91.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230377</td>\n",
       "      <td>0.550165</td>\n",
       "      <td>0.678383</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.302521</td>\n",
       "      <td>0.512938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085583</td>\n",
       "      <td>0.100461</td>\n",
       "      <td>0.049937</td>\n",
       "      <td>0.499935</td>\n",
       "      <td>0.537906</td>\n",
       "      <td>-0.037971</td>\n",
       "      <td>356.530636</td>\n",
       "      <td>259.872359</td>\n",
       "      <td>139.373125</td>\n",
       "      <td>0.374739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>92.39</td>\n",
       "      <td>91.81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.226961</td>\n",
       "      <td>0.530850</td>\n",
       "      <td>0.662016</td>\n",
       "      <td>0.665517</td>\n",
       "      <td>0.309621</td>\n",
       "      <td>0.603648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118697</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.040774</td>\n",
       "      <td>0.490277</td>\n",
       "      <td>0.583261</td>\n",
       "      <td>-0.092984</td>\n",
       "      <td>359.897075</td>\n",
       "      <td>306.882580</td>\n",
       "      <td>141.712500</td>\n",
       "      <td>0.481327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>114.80</td>\n",
       "      <td>91.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276465</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.288594</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052871</td>\n",
       "      <td>0.173296</td>\n",
       "      <td>0.076763</td>\n",
       "      <td>0.536352</td>\n",
       "      <td>0.524493</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>372.720173</td>\n",
       "      <td>234.122715</td>\n",
       "      <td>141.959375</td>\n",
       "      <td>0.016799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  MooreRating_x  MooreRating_y  Seed_x  3ptRate_x    Ast%_x  \\\n",
       "0  2010.0          91.81          78.17       4   0.153633  0.562874   \n",
       "1  2010.0          91.81          82.29       4   0.153633  0.562874   \n",
       "2  2010.0          95.45          91.81       1   0.230377  0.550165   \n",
       "3  2010.0          92.39          91.81       2   0.226961  0.530850   \n",
       "4  2010.0         114.80          91.81       1   0.276465  0.623000   \n",
       "\n",
       "      FT%_x  OppFT%_x  Opp3ptRate_x  OppAst%_x  ...  xOffyOffFTRateDiff  \\\n",
       "0  0.726562  0.687204      0.318363   0.449704  ...            0.103332   \n",
       "1  0.726562  0.687204      0.318363   0.449704  ...            0.137651   \n",
       "2  0.678383  0.679487      0.302521   0.512938  ...           -0.085583   \n",
       "3  0.662016  0.665517      0.309621   0.603648  ...           -0.118697   \n",
       "4  0.723077  0.630556      0.288594   0.486111  ...           -0.052871   \n",
       "\n",
       "   AbsxOffyDefAstDiff  AbsyOffxDefAstDiff  xOffyDefAstAvg  yOffxDefAstAvg  \\\n",
       "0            0.046362            0.116533        0.539693        0.507970   \n",
       "1            0.109423            0.216030        0.617586        0.557719   \n",
       "2            0.100461            0.049937        0.499935        0.537906   \n",
       "3            0.081146            0.040774        0.490277        0.583261   \n",
       "4            0.173296            0.076763        0.536352        0.524493   \n",
       "\n",
       "   xOffyOffAstDiff  TotalPossVarSum  GameScoreVarSum  AvgTotalPoss  \\\n",
       "0         0.031723       323.329209       249.795260    142.390152   \n",
       "1         0.059867       498.758776       240.489802    139.451000   \n",
       "2        -0.037971       356.530636       259.872359    139.373125   \n",
       "3        -0.092984       359.897075       306.882580    141.712500   \n",
       "4         0.011859       372.720173       234.122715    141.959375   \n",
       "\n",
       "   MooreNaiveUpsetProbability  \n",
       "0                    0.111138  \n",
       "1                    0.192651  \n",
       "2                    0.374739  \n",
       "3                    0.481327  \n",
       "4                    0.016799  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# game data outputted from W1_DataCleaning.ipynb, with stats, goes back to 2010\n",
    "game_data = pd.read_csv('mydata/womens/matchups.csv')\n",
    "game_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>MooreRating_x</th>\n",
       "      <th>MooreRating_y</th>\n",
       "      <th>Seed_x</th>\n",
       "      <th>Seed_y</th>\n",
       "      <th>Upset</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>SeedDiff</th>\n",
       "      <th>MooreRatingPredictedSpread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>86.08</td>\n",
       "      <td>66.75</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>19.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>86.08</td>\n",
       "      <td>84.71</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>95.16</td>\n",
       "      <td>66.20</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-13</td>\n",
       "      <td>28.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>95.16</td>\n",
       "      <td>79.34</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>15.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>82.85</td>\n",
       "      <td>79.34</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  MooreRating_x  MooreRating_y  Seed_x  Seed_y  Upset  ScoreDiff  \\\n",
       "0  2005.0          86.08          66.75       5      12      0       22.0   \n",
       "1  2005.0          86.08          84.71       5       4      0        9.0   \n",
       "2  2005.0          95.16          66.20       2      15      0       21.0   \n",
       "3  2005.0          95.16          79.34       2      10      0       23.0   \n",
       "4  2005.0          82.85          79.34       7      10      1       -3.0   \n",
       "\n",
       "   SeedDiff  MooreRatingPredictedSpread  \n",
       "0        -7                       19.33  \n",
       "1         1                        1.37  \n",
       "2       -13                       28.96  \n",
       "3        -8                       15.82  \n",
       "4        -3                        3.51  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# game data outputted from W1_DataCleaning.ipynb, no stats, goes back to 2005\n",
    "game_data_no_stats = pd.read_csv('mydata/womens/matchups_no_stats.csv')\n",
    "game_data_no_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_data_no_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stats = game_data.drop(columns = ['Upset'])\n",
    "y_stats = game_data['Upset']\n",
    "X_no_stats = game_data_no_stats.drop(columns = ['Upset'])\n",
    "y_no_stats = game_data_no_stats['Upset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regularization for feature selection\n",
    "# coefficients range from 0.02 to ~2000\n",
    "# each coefficient is 6% larger than last, there are 200 coefficients in total\n",
    "lasso_reg = [0.02 * (1.06) ** i for i in range(200)]\n",
    "\n",
    "# ridge regularization to prevent overfitting\n",
    "ridge_reg = [1e-7, 3e-7, 1e-6, 3e-6, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3]\n",
    "\n",
    "# scale used to scale columns before applying regularization\n",
    "scale = StandardScaler()\n",
    "\n",
    "def train_logistic_regression(stats, features = None):\n",
    "    \n",
    "    # if using the stats dataframe or the non stats dataframe\n",
    "    if stats:\n",
    "        X = X_stats\n",
    "        y = y_stats\n",
    "        lasso_coef = lasso_reg\n",
    "    else:\n",
    "        X = X_stats\n",
    "        y = y_stats\n",
    "        lasso_coef = [None]\n",
    "        \n",
    "    # list/dictionaries to store results\n",
    "    feature_list = []\n",
    "    scores = {}\n",
    "    model_coefs = []\n",
    "    models = []\n",
    "    num_features = []\n",
    "    \n",
    "    # for each possible lasso regularization coefficient\n",
    "    for c in tqdm(lasso_coef):\n",
    "        \n",
    "        if c is not None:\n",
    "            # dont use season as a feature, use inputted features if given\n",
    "            if features:\n",
    "                X_lasso = X[features]\n",
    "            else:\n",
    "                X_lasso = X.drop(columns = ['Season'])\n",
    "\n",
    "            # scale columns before regularization\n",
    "            X_lasso = pd.DataFrame(scale.fit_transform(X_lasso), columns = X_lasso.columns)\n",
    "\n",
    "            # fit L1 logistic regression for feature selection\n",
    "            lasso = LogisticRegression(penalty = 'l1', C = c, random_state = 0, solver = 'saga', max_iter = 10000).fit(X_lasso, y)\n",
    "\n",
    "            # filter for the columns with nonzero coefficients and the season column\n",
    "            zero_cols = []\n",
    "            if features:\n",
    "                zero_cols = list(set(X.drop(columns = ['Season']).columns) - set(features))\n",
    "            for i in range(len(lasso.coef_[0])):\n",
    "                if lasso.coef_[0][i] == 0.0:\n",
    "                    zero_cols.append(X_lasso.columns[i])\n",
    "            nonzero_X = X.drop(columns = zero_cols)\n",
    "        else:\n",
    "            nonzero_X = X.copy()\n",
    "        \n",
    "        # if there is at least 1 nonzero column and the same amount of features hasn't already been built\n",
    "        if (len(nonzero_X.columns) > 1 and (len(nonzero_X.columns) - 1) not in num_features):\n",
    "            \n",
    "            # try each L2 regularization coefficient\n",
    "            for c2 in ridge_reg:\n",
    "                \n",
    "                # cross validate over each season\n",
    "                for season in list(X['Season'].unique()):\n",
    "                    \n",
    "                    # add season to scores dictionary\n",
    "                    if season not in scores:\n",
    "                        scores[season] = []\n",
    "                        \n",
    "                    # split into train and validation sets\n",
    "                    X_train = nonzero_X[nonzero_X['Season'] != season].drop(columns = ['Season'])\n",
    "                    X_val = nonzero_X[nonzero_X['Season'] == season].drop(columns = ['Season'])\n",
    "                    X_train = pd.DataFrame(scale.fit_transform(X_train), columns = X_train.columns)\n",
    "                    X_val = pd.DataFrame(scale.transform(X_val), columns = X_val.columns)\n",
    "                    y_train = y[X_train.index]\n",
    "                    y_val = y[X_val.index]\n",
    "                    \n",
    "                    # fit logistic regression\n",
    "                    log_model = LogisticRegression(penalty = 'l2', C = c2, max_iter = 10000, random_state = 0, solver = \"sag\").fit(X_train, y_train)\n",
    "                    \n",
    "                    # predict win probabilities\n",
    "                    predictions = log_model.predict_proba(X_val)\n",
    "                    \n",
    "                    # calculate log loss and store\n",
    "                    val_score = log_loss(y_val, predictions)\n",
    "                    scores[season].append(val_score)\n",
    "                    \n",
    "                # retrain model on full dataset for coefficients\n",
    "                log_model = LogisticRegression(penalty = 'l2', C = c2, max_iter = 10000, random_state = 0, solver = \"sag\").fit(pd.DataFrame(scale.fit_transform(nonzero_X), columns = nonzero_X.columns).drop(columns = ['Season']), y)\n",
    "                \n",
    "                # store model details\n",
    "                feature_list.append(nonzero_X.drop(columns = ['Season']).columns)\n",
    "                num_features.append(len(nonzero_X.drop(columns = ['Season']).columns))\n",
    "                models.append(log_model)\n",
    "                model_coefs.append({'lasso_coef': c, 'ridge_coef': c2})\n",
    "                \n",
    "    # if using stats dataframe, add nulls for scores of years we don't have data for\n",
    "    if 2005 not in scores:\n",
    "        scores[2005] = [None for i in range(len(models))]\n",
    "        scores[2006] = [None for i in range(len(models))]\n",
    "        scores[2007] = [None for i in range(len(models))]\n",
    "        scores[2008] = [None for i in range(len(models))]\n",
    "        scores[2009] = [None for i in range(len(models))]\n",
    "                \n",
    "    # return dataframe of results\n",
    "    return pd.DataFrame({'Type': ['log' for i in range(len(models))],\n",
    "                         'Num_Features': num_features,\n",
    "                         'Features': feature_list,\n",
    "                         'Model': models,\n",
    "                         'Model_Coef': model_coefs,\n",
    "                         'Stats': [stats for i in range(len(models))],\n",
    "                         '2005_Score': scores[2005],\n",
    "                         '2006_Score': scores[2006],\n",
    "                         '2007_Score': scores[2007],\n",
    "                         '2008_Score': scores[2008],\n",
    "                         '2009_Score': scores[2009],\n",
    "                         '2010_Score': scores[2010],\n",
    "                         '2011_Score': scores[2011],\n",
    "                         '2012_Score': scores[2012],\n",
    "                         '2013_Score': scores[2013],\n",
    "                         '2014_Score': scores[2014],\n",
    "                         '2015_Score': scores[2015],\n",
    "                         '2016_Score': scores[2016],\n",
    "                         '2017_Score': scores[2017],\n",
    "                         '2018_Score': scores[2018],\n",
    "                         '2019_Score': scores[2019]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "The purpose of the knn model is due to the high collinearity between SeedDiff and MooreRatingDiff being a problem for the logistic regression. Therefore, it will only use the dataframe without stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10 + i for i in range(90)]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "def train_knn():\n",
    "    \n",
    "    # to store model info during cross validation\n",
    "    scores = {}\n",
    "    model_coefs = []\n",
    "    models = []\n",
    "    \n",
    "    # for repeatable randomization\n",
    "    random.seed(0)\n",
    "    \n",
    "    # train 50 models\n",
    "    for i in range(50):\n",
    "        \n",
    "        knn_params = {'n_neighbors': ks[random.randint(0, len(ks) - 1)],\n",
    "                     'weights': weights[random.randint(0, len(weights) - 1)]}\n",
    "        \n",
    "        # for each season\n",
    "        for season in list(X['Season'].unique()):\n",
    "\n",
    "            # add season to scores dictionary\n",
    "            if season not in scores:\n",
    "                scores[season] = []\n",
    "\n",
    "                # split into train and validation sets\n",
    "                X_train = X[X['Season'] != season].drop(columns = ['Season'])\n",
    "                X_val = X[X['Season'] == season].drop(columns = ['Season'])\n",
    "                X_train = pd.DataFrame(scale.fit_transform(X_train), columns = X_train.columns)\n",
    "                X_val = pd.DataFrame(scale.transform(X_val), columns = X_val.columns)\n",
    "                y_train = y[X_train.index]\n",
    "                y_val = y[X_val.index]\n",
    "\n",
    "                # fit knn\n",
    "                knn_model = KNeighborsClassifier(n_neighbors = knn_params['n_neighbors'],\n",
    "                                                 weights = knn_params['weights']).fit(X_train, y_train)\n",
    "\n",
    "                # predict win probabilities\n",
    "                predictions = knn_model.predict_proba(X_val)\n",
    "\n",
    "                # calculate log loss and store\n",
    "                val_score = log_loss(y_val, predictions)\n",
    "                scores[season].append(val_score)\n",
    "                \n",
    "        # store model details, no need to store KNN model yet\n",
    "        models.append(None)\n",
    "        model_coefs.append({'k': knn_params['n_neighbors'], 'weights': knn_params['weights']})\n",
    "    \n",
    "    # return dataframe of results\n",
    "    return pd.DataFrame({'Type': ['knn' for i in range(len(models))],\n",
    "                         'Num_Features': 'All',\n",
    "                         'Features': 'All',\n",
    "                         'Model': models,\n",
    "                         'Model_Coef': model_coefs,\n",
    "                         'Stats': [stats for i in range(len(models))],\n",
    "                         '2005_Score': scores[2005],\n",
    "                         '2006_Score': scores[2006],\n",
    "                         '2007_Score': scores[2007],\n",
    "                         '2008_Score': scores[2008],\n",
    "                         '2009_Score': scores[2009],\n",
    "                         '2010_Score': scores[2010],\n",
    "                         '2011_Score': scores[2011],\n",
    "                         '2012_Score': scores[2012],\n",
    "                         '2013_Score': scores[2013],\n",
    "                         '2014_Score': scores[2014],\n",
    "                         '2015_Score': scores[2015],\n",
    "                         '2016_Score': scores[2016],\n",
    "                         '2017_Score': scores[2017],\n",
    "                         '2018_Score': scores[2018],\n",
    "                         '2019_Score': scores[2019]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the models\n",
    "log_results1 = train_logistic_regression(True)\n",
    "log_results2 = train_logistic_regression(False)\n",
    "knn_results = train_knn()\n",
    "final_results = pd.concat([log_results1, log_results2, knn_results], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentiles of scores in relation to other models\n",
    "score_cols = []\n",
    "for col in final_results.columns:\n",
    "    if col.endswith(\"Score\"):\n",
    "        score_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average score and average percentile\n",
    "final_results['Avg_Score'] = final_results[score_cols].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show feature importances of given model by results row index\n",
    "def features(row_index):\n",
    "    \n",
    "    # if model is logistic regression, return coefficients\n",
    "    if final_results.loc[row_index, 'Type'] == 'log':\n",
    "        \n",
    "        model_features = list(final_results.loc[row_index, 'Features'])\n",
    "        sign_list = []\n",
    "        coef_list = []\n",
    "        for i in range(len(model_features)):\n",
    "            coef = round(model.coef_[0][i], 3)\n",
    "            coef_list.append(coef)\n",
    "            if coef > 0:\n",
    "                sign_list.append('+')\n",
    "            else:\n",
    "                sign_list.append('-')\n",
    "        \n",
    "        return_df =  pd.DataFrame({'Feature': model_features,\n",
    "                             'Sign': sign_list,\n",
    "                            'Coefficient': coef_list})\n",
    "        return return_df.reindex(return_df['Coefficient'].abs().sort_values(ascending = False).index)\n",
    "        \n",
    "    # KNN doesn't really have a feature importance\n",
    "    else:\n",
    "        print('All features have equal weight in KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "pd.set_option('display.max_rows', None)\n",
    "final_results[['Type', 'Model_Coef', 'Avg_Score']].sort_values(by = ['Avg_Score'], ascending = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
