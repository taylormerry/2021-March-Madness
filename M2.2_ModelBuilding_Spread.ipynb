{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Build logistic regression, random forest, and XGBoost models to predict the probability of an upset in the NCAA tournament\n",
    "\n",
    "Based on data output in M1_DataCleaning.ipynb, model used in M3_Predictions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamrankRating_x</th>\n",
       "      <th>TrankRating_x</th>\n",
       "      <th>OE_x</th>\n",
       "      <th>DE_x</th>\n",
       "      <th>Tempo_x</th>\n",
       "      <th>Seed_x</th>\n",
       "      <th>3ptRate_x</th>\n",
       "      <th>Ast%_x</th>\n",
       "      <th>FT%_x</th>\n",
       "      <th>...</th>\n",
       "      <th>xOffyDefFTRateAvg</th>\n",
       "      <th>yOffxDefFTRateAvg</th>\n",
       "      <th>AbsxOffyDefAstDiff</th>\n",
       "      <th>AbsyOffxDefAstDiff</th>\n",
       "      <th>xOffyDefAstAvg</th>\n",
       "      <th>yOffxDefAstAvg</th>\n",
       "      <th>TotalPossVarSum</th>\n",
       "      <th>GameScoreVarSum</th>\n",
       "      <th>TrankNaiveUpsetProbability</th>\n",
       "      <th>TeamrankNaiveUpsetProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.960742</td>\n",
       "      <td>117.213494</td>\n",
       "      <td>88.761128</td>\n",
       "      <td>73.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.390996</td>\n",
       "      <td>0.522826</td>\n",
       "      <td>0.694618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380141</td>\n",
       "      <td>0.330101</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.152258</td>\n",
       "      <td>0.528512</td>\n",
       "      <td>0.552607</td>\n",
       "      <td>342.200873</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.022079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.960742</td>\n",
       "      <td>117.213494</td>\n",
       "      <td>88.761128</td>\n",
       "      <td>73.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.390996</td>\n",
       "      <td>0.522826</td>\n",
       "      <td>0.694618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396759</td>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.109056</td>\n",
       "      <td>0.520698</td>\n",
       "      <td>0.531006</td>\n",
       "      <td>295.048054</td>\n",
       "      <td>0.047594</td>\n",
       "      <td>0.312558</td>\n",
       "      <td>0.323143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.927155</td>\n",
       "      <td>115.187217</td>\n",
       "      <td>92.329124</td>\n",
       "      <td>65.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.371802</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.750341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403042</td>\n",
       "      <td>0.342810</td>\n",
       "      <td>0.092145</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.564642</td>\n",
       "      <td>0.594836</td>\n",
       "      <td>269.327900</td>\n",
       "      <td>0.072884</td>\n",
       "      <td>0.459461</td>\n",
       "      <td>0.493502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.981585</td>\n",
       "      <td>120.970641</td>\n",
       "      <td>85.610492</td>\n",
       "      <td>69.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.291796</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.707756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360666</td>\n",
       "      <td>0.341935</td>\n",
       "      <td>0.079363</td>\n",
       "      <td>0.078373</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>0.574597</td>\n",
       "      <td>266.467752</td>\n",
       "      <td>0.058420</td>\n",
       "      <td>0.030979</td>\n",
       "      <td>0.039768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.981585</td>\n",
       "      <td>120.970641</td>\n",
       "      <td>85.610492</td>\n",
       "      <td>69.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.291796</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.707756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350930</td>\n",
       "      <td>0.316380</td>\n",
       "      <td>0.080697</td>\n",
       "      <td>0.071639</td>\n",
       "      <td>0.587224</td>\n",
       "      <td>0.571230</td>\n",
       "      <td>309.871774</td>\n",
       "      <td>0.046553</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.069552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  TeamrankRating_x  TrankRating_x        OE_x       DE_x  Tempo_x  \\\n",
       "0  2008.0              28.5       0.960742  117.213494  88.761128     73.7   \n",
       "1  2008.0              28.5       0.960742  117.213494  88.761128     73.7   \n",
       "2  2008.0              23.6       0.927155  115.187217  92.329124     65.8   \n",
       "3  2008.0              32.4       0.981585  120.970641  85.610492     69.5   \n",
       "4  2008.0              32.4       0.981585  120.970641  85.610492     69.5   \n",
       "\n",
       "   Seed_x  3ptRate_x    Ast%_x     FT%_x  ...  xOffyDefFTRateAvg  \\\n",
       "0       2   0.390996  0.522826  0.694618  ...           0.380141   \n",
       "1       2   0.390996  0.522826  0.694618  ...           0.396759   \n",
       "2       3   0.371802  0.610714  0.750341  ...           0.403042   \n",
       "3       1   0.291796  0.627572  0.707756  ...           0.360666   \n",
       "4       1   0.291796  0.627572  0.707756  ...           0.350930   \n",
       "\n",
       "   yOffxDefFTRateAvg  AbsxOffyDefAstDiff  AbsyOffxDefAstDiff  xOffyDefAstAvg  \\\n",
       "0           0.330101            0.011372            0.152258        0.528512   \n",
       "1           0.345179            0.004257            0.109056        0.520698   \n",
       "2           0.342810            0.092145            0.018604        0.564642   \n",
       "3           0.341935            0.079363            0.078373        0.587891   \n",
       "4           0.316380            0.080697            0.071639        0.587224   \n",
       "\n",
       "   yOffxDefAstAvg  TotalPossVarSum  GameScoreVarSum  \\\n",
       "0        0.552607       342.200873         0.030100   \n",
       "1        0.531006       295.048054         0.047594   \n",
       "2        0.594836       269.327900         0.072884   \n",
       "3        0.574597       266.467752         0.058420   \n",
       "4        0.571230       309.871774         0.046553   \n",
       "\n",
       "   TrankNaiveUpsetProbability  TeamrankNaiveUpsetProbability  \n",
       "0                    0.011556                       0.022079  \n",
       "1                    0.312558                       0.323143  \n",
       "2                    0.459461                       0.493502  \n",
       "3                    0.030979                       0.039768  \n",
       "4                    0.084577                       0.069552  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matchup data outputted from M1_DataCleaning.ipynb\n",
    "matchups = pd.read_csv('mydata/mens/matchups_with1v16and2v15.csv')\n",
    "matchups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = matchups['ScorePerPossDiff']\n",
    "X = matchups.drop(columns = ['Upset', 'ScorePerPossDiff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Num_Features</th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Model_Coef</th>\n",
       "      <th>2008_Score</th>\n",
       "      <th>2009_Score</th>\n",
       "      <th>2010_Score</th>\n",
       "      <th>2011_Score</th>\n",
       "      <th>2012_Score</th>\n",
       "      <th>2013_Score</th>\n",
       "      <th>2014_Score</th>\n",
       "      <th>2015_Score</th>\n",
       "      <th>2016_Score</th>\n",
       "      <th>2017_Score</th>\n",
       "      <th>2018_Score</th>\n",
       "      <th>2019_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>RandomForestRegressor(max_features=26, min_sam...</td>\n",
       "      <td>{'max_features': 26, 'max_depth': None, 'min_s...</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>0.030588</td>\n",
       "      <td>0.027593</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>0.043503</td>\n",
       "      <td>0.030992</td>\n",
       "      <td>0.023487</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>0.027618</td>\n",
       "      <td>0.032460</td>\n",
       "      <td>0.032098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>RandomForestRegressor(max_features=30, min_sam...</td>\n",
       "      <td>{'max_features': 30, 'max_depth': None, 'min_s...</td>\n",
       "      <td>0.034537</td>\n",
       "      <td>0.029874</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.043381</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.033808</td>\n",
       "      <td>0.026079</td>\n",
       "      <td>0.034656</td>\n",
       "      <td>0.033101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>RandomForestRegressor(max_depth=20, max_featur...</td>\n",
       "      <td>{'max_features': 28, 'max_depth': 20, 'min_sam...</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.030089</td>\n",
       "      <td>0.026526</td>\n",
       "      <td>0.034218</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.043172</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>0.023230</td>\n",
       "      <td>0.034228</td>\n",
       "      <td>0.025750</td>\n",
       "      <td>0.034560</td>\n",
       "      <td>0.033075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>RandomForestRegressor(max_depth=20, max_featur...</td>\n",
       "      <td>{'max_features': 30, 'max_depth': 20, 'min_sam...</td>\n",
       "      <td>0.036128</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>0.027804</td>\n",
       "      <td>0.036257</td>\n",
       "      <td>0.021156</td>\n",
       "      <td>0.043208</td>\n",
       "      <td>0.030860</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.032487</td>\n",
       "      <td>0.032211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>RandomForestRegressor(max_features=26, min_sam...</td>\n",
       "      <td>{'max_features': 26, 'max_depth': None, 'min_s...</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>0.039097</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>0.025358</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>0.032193</td>\n",
       "      <td>0.033994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type Num_Features Features  \\\n",
       "0   rf          All      All   \n",
       "1   rf          All      All   \n",
       "2   rf          All      All   \n",
       "3   rf          All      All   \n",
       "4   rf          All      All   \n",
       "\n",
       "                                               Model  \\\n",
       "0  RandomForestRegressor(max_features=26, min_sam...   \n",
       "1  RandomForestRegressor(max_features=30, min_sam...   \n",
       "2  RandomForestRegressor(max_depth=20, max_featur...   \n",
       "3  RandomForestRegressor(max_depth=20, max_featur...   \n",
       "4  RandomForestRegressor(max_features=26, min_sam...   \n",
       "\n",
       "                                          Model_Coef  2008_Score  2009_Score  \\\n",
       "0  {'max_features': 26, 'max_depth': None, 'min_s...    0.036087    0.030588   \n",
       "1  {'max_features': 30, 'max_depth': None, 'min_s...    0.034537    0.029874   \n",
       "2  {'max_features': 28, 'max_depth': 20, 'min_sam...    0.034165    0.030089   \n",
       "3  {'max_features': 30, 'max_depth': 20, 'min_sam...    0.036128    0.030680   \n",
       "4  {'max_features': 26, 'max_depth': None, 'min_s...    0.039553    0.032409   \n",
       "\n",
       "   2010_Score  2011_Score  2012_Score  2013_Score  2014_Score  2015_Score  \\\n",
       "0    0.027593    0.036160    0.021032    0.043503    0.030992    0.023487   \n",
       "1    0.026415    0.034842    0.021782    0.043381    0.032298    0.023499   \n",
       "2    0.026526    0.034218    0.021494    0.043172    0.032083    0.023230   \n",
       "3    0.027804    0.036257    0.021156    0.043208    0.030860    0.023331   \n",
       "4    0.027401    0.039097    0.023398    0.045343    0.032957    0.025358   \n",
       "\n",
       "   2016_Score  2017_Score  2018_Score  2019_Score  \n",
       "0    0.035227    0.027618    0.032460    0.032098  \n",
       "1    0.033808    0.026079    0.034656    0.033101  \n",
       "2    0.034228    0.025750    0.034560    0.033075  \n",
       "3    0.035110    0.027765    0.032487    0.032211  \n",
       "4    0.037614    0.031062    0.032193    0.033994  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in previous results to not duplicate params that have already been tested\n",
    "prev_results = pd.read_csv('mydata/training_results_spread.csv')\n",
    "prev_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regularization for feature selection\n",
    "# coefficients range from 0.000001 to 0.1\n",
    "# each coefficient is 12.2% larger than last, there are 100 coefficients in total\n",
    "lasso_reg = [1e-6 * (1.122) ** i for i in range(100)]\n",
    "\n",
    "# ridge regularization to prevent overfitting\n",
    "ridge_reg = [1e-7, 3e-7, 1e-6, 3e-6, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 1e0, 3e0, 1e1, 3e1, 1e2, 3e2, 1e3, 3e3, 1e4, 3e4, 1e5, 3e5, 1e6, 3e6, 1e7, 3e7]\n",
    "\n",
    "# scale used to scale columns before applying regularization\n",
    "scale = StandardScaler()\n",
    "\n",
    "def train_linear_regression():\n",
    "    \n",
    "    # list/dictionaries to store results\n",
    "    feature_list = []\n",
    "    scores = {}\n",
    "    model_coefs = []\n",
    "    models = []\n",
    "    num_features = []\n",
    "    \n",
    "    # for each possible lasso regularization coefficient\n",
    "    for c in tqdm(lasso_reg):\n",
    "        \n",
    "        # dont use season as a feature\n",
    "        X_lasso = X.drop(columns = ['Season'])\n",
    "        \n",
    "        # scale columns before regularization\n",
    "        X_lasso = pd.DataFrame(scale.fit_transform(X_lasso), columns = X_lasso.columns)\n",
    "        \n",
    "        # fit L1 logistic regression for feature selection\n",
    "        lasso = Lasso(alpha = c, random_state = 0, max_iter = 10000).fit(X_lasso, y)\n",
    "        \n",
    "        # filter for the columns with nonzero coefficients and the season column\n",
    "        zero_cols = []\n",
    "        for i in range(len(lasso.coef_)):\n",
    "            if lasso.coef_[i] == 0.0:\n",
    "                zero_cols.append(X_lasso.columns[i])\n",
    "        nonzero_X = X.drop(columns = zero_cols)\n",
    "        \n",
    "        # if there is at least 1 nonzero column and the same amount of features hasn't already been built\n",
    "        if (len(nonzero_X.columns) > 1 and (len(nonzero_X.columns) - 1) not in num_features):\n",
    "            \n",
    "            # try each L2 regularization coefficient\n",
    "            for c2 in ridge_reg:\n",
    "                \n",
    "                # cross validate over each season\n",
    "                for season in list(X['Season'].unique()):\n",
    "                    \n",
    "                    # add season to scores dictionary\n",
    "                    if season not in scores:\n",
    "                        scores[season] = []\n",
    "                        \n",
    "                    # split into train and validation sets\n",
    "                    X_train = nonzero_X[nonzero_X['Season'] != season].drop(columns = ['Season'])\n",
    "                    X_val = nonzero_X[nonzero_X['Season'] == season].drop(columns = ['Season'])\n",
    "                    X_train = pd.DataFrame(scale.fit_transform(X_train), columns = X_train.columns)\n",
    "                    X_val = pd.DataFrame(scale.transform(X_val), columns = X_val.columns)\n",
    "                    y_train = y[X_train.index]\n",
    "                    y_val = y[X_val.index]\n",
    "                    \n",
    "                    # fit logistic regression\n",
    "                    lin_model = Ridge(alpha = c2, max_iter = 10000, random_state = 0).fit(X_train, y_train)\n",
    "                    \n",
    "                    # predict win probabilities\n",
    "                    predictions = lin_model.predict(X_val)\n",
    "                    \n",
    "                    # calculate log loss and store\n",
    "                    val_score = mean_squared_error(y_val, predictions)\n",
    "                    scores[season].append(val_score)\n",
    "                    \n",
    "                # retrain model on full dataset for coefficients\n",
    "                lin_model = Ridge(alpha = c2, max_iter = 10000, random_state = 0).fit(pd.DataFrame(scale.fit_transform(nonzero_X), columns = nonzero_X.columns).drop(columns = ['Season']), y)\n",
    "                \n",
    "                # store model details\n",
    "                feature_list.append(nonzero_X.drop(columns = ['Season']).columns)\n",
    "                num_features.append(len(nonzero_X.drop(columns = ['Season']).columns))\n",
    "                models.append(lin_model)\n",
    "                model_coefs.append({'lasso_coef': c, 'ridge_coef': c2})\n",
    "                \n",
    "    # return dataframe of results\n",
    "    return pd.DataFrame({'Type': ['log' for i in range(len(models))],\n",
    "                         'Num_Features': num_features,\n",
    "                         'Features': feature_list,\n",
    "                         'Model': models,\n",
    "                         'Model_Coef': model_coefs,\n",
    "                         '2008_Score': scores[2008],\n",
    "                         '2009_Score': scores[2009],\n",
    "                         '2010_Score': scores[2010],\n",
    "                         '2011_Score': scores[2011],\n",
    "                         '2012_Score': scores[2012],\n",
    "                         '2013_Score': scores[2013],\n",
    "                         '2014_Score': scores[2014],\n",
    "                         '2015_Score': scores[2015],\n",
    "                         '2016_Score': scores[2016],\n",
    "                         '2017_Score': scores[2017],\n",
    "                         '2018_Score': scores[2018],\n",
    "                         '2019_Score': scores[2019]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest paramaters\n",
    "max_features_list = [5, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 35, 40]\n",
    "rf_max_depths = [5, 10, 15, 20, None]\n",
    "min_samples = [0.01, 0.03, 0.1, 0.3]\n",
    "\n",
    "def train_random_forest():\n",
    "    \n",
    "    # list/dictionaries to store results\n",
    "    scores = {}\n",
    "    models = []\n",
    "    model_coefs = []\n",
    "    \n",
    "    # fit 100 models\n",
    "    for i in tqdm(range(20)):\n",
    "        \n",
    "        # randomly generate random forest params\n",
    "        rf_params = {'max_features': max_features_list[random.randint(0, len(max_features_list) - 1)],\n",
    "                     'max_depth': rf_max_depths[random.randint(0, len(rf_max_depths) - 1)],\n",
    "                     'min_samples_leaf': min_samples[random.randint(0, len(min_samples) - 1)]\n",
    "                    }\n",
    "        \n",
    "        # keep generating params if they've already been tested\n",
    "        while rf_params in list(prev_results['Model_Coef']):\n",
    "            rf_params = {'max_features': max_features_list[random.randint(0, len(max_features_list) - 1)],\n",
    "                         'max_depth': rf_max_depths[random.randint(0, len(rf_max_depths) - 1)],\n",
    "                         'min_samples_leaf': min_samples[random.randint(0, len(min_samples) - 1)]\n",
    "                        }\n",
    "        \n",
    "        # cross validate over each season\n",
    "        for season in list(X['Season'].unique()):\n",
    "            \n",
    "            # add season to scores dictionary\n",
    "            if season not in scores:\n",
    "                scores[season] = []\n",
    "            \n",
    "            # split into train and validation sets\n",
    "            X_train = X[X['Season'] != season].drop(columns = ['Season'])\n",
    "            X_val = X[X['Season'] == season].drop(columns = ['Season'])\n",
    "            y_train = y[X_train.index]\n",
    "            y_val = y[X_val.index]\n",
    "            \n",
    "            # fit random forest model\n",
    "            rf_model = RandomForestRegressor(n_estimators = 500,\n",
    "                                             max_depth = rf_params['max_depth'],\n",
    "                                             min_samples_leaf = rf_params['min_samples_leaf'],\n",
    "                                             max_features = rf_params['max_features'],\n",
    "                                             random_state = 0).fit(X_train, y_train)\n",
    "            \n",
    "            # predict win probabilities\n",
    "            predictions = rf_model.predict(X_val)\n",
    "            \n",
    "            # calculate log loss and store score\n",
    "            val_score = mean_squared_error(y_val, predictions)\n",
    "            scores[season].append(val_score)\n",
    "            \n",
    "        # retrain model on full dataset for feature importances\n",
    "        rf_model = RandomForestRegressor(n_estimators = 500,\n",
    "                                         max_depth = rf_params['max_depth'],\n",
    "                                         min_samples_leaf = rf_params['min_samples_leaf'],\n",
    "                                         max_features = rf_params['max_features'],\n",
    "                                         random_state = 0).fit(X.drop(columns = ['Season']), y)\n",
    "        \n",
    "        # store model details\n",
    "        model_coefs.append(rf_params)\n",
    "        models.append(rf_model)\n",
    "        \n",
    "    # return dataframe of results\n",
    "    return pd.DataFrame({'Type': ['rf' for i in range(len(models))],\n",
    "                         'Num_Features': ['All' for i in range(len(models))],\n",
    "                         'Features': ['All' for i in range(len(models))],\n",
    "                         'Model': models,\n",
    "                         'Model_Coef': model_coefs,\n",
    "                         '2008_Score': scores[2008],\n",
    "                         '2009_Score': scores[2009],\n",
    "                         '2010_Score': scores[2010],\n",
    "                         '2011_Score': scores[2011],\n",
    "                         '2012_Score': scores[2012],\n",
    "                         '2013_Score': scores[2013],\n",
    "                         '2014_Score': scores[2014],\n",
    "                         '2015_Score': scores[2015],\n",
    "                         '2016_Score': scores[2016],\n",
    "                         '2017_Score': scores[2017],\n",
    "                         '2018_Score': scores[2018],\n",
    "                         '2019_Score': scores[2019]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters\n",
    "etas = [0.03, 0.1, 0.3, 1, 3]\n",
    "xgb_max_depths = [8, 10, 12]\n",
    "min_child_weights = [5, 6, 7]\n",
    "gammas = [0.3]\n",
    "subsamples = [0.95, 1]\n",
    "lambdas = [0.3, 1, 3, 10, 30, 100, 300, 1000]\n",
    "\n",
    "def train_xgboost():\n",
    "    \n",
    "    # list/dictionaries to store results\n",
    "    scores = {}\n",
    "    models = []\n",
    "    model_coefs = []\n",
    "    \n",
    "    # fit 100 models\n",
    "    for i in tqdm(range(50)):\n",
    "        \n",
    "        # randomly generate XGBoost params\n",
    "        xgb_params = {'eta': etas[random.randint(0, len(etas) - 1)],\n",
    "                      'max_depth': xgb_max_depths[random.randint(0, len(xgb_max_depths) - 1)],\n",
    "                      'min_child_weight': min_child_weights[random.randint(0, len(min_child_weights) - 1)],\n",
    "                      'gamma': gammas[random.randint(0, len(gammas) - 1)],\n",
    "                      'subsample': subsamples[random.randint(0, len(subsamples) - 1)],\n",
    "                      'lambda': lambdas[random.randint(0, len(lambdas) - 1)],\n",
    "                      'random_state': 0\n",
    "                     }\n",
    "        # keep randomly generating if params have already been tested\n",
    "        while xgb_params in list(prev_results['Model_Coef']):\n",
    "            # randomly generate XGBoost params\n",
    "            xgb_params = {'eta': etas[random.randint(0, len(etas) - 1)],\n",
    "                          'max_depth': xgb_max_depths[random.randint(0, len(xgb_max_depths) - 1)],\n",
    "                          'min_child_weight': min_child_weights[random.randint(0, len(min_child_weights) - 1)],\n",
    "                          'gamma': gammas[random.randint(0, len(gammas) - 1)],\n",
    "                          'subsample': subsamples[random.randint(0, len(subsamples) - 1)],\n",
    "                          'lambda': lambdas[random.randint(0, len(lambdas) - 1)],\n",
    "                          'random_state': 0\n",
    "                         }\n",
    "        \n",
    "        # cross validate over each season\n",
    "        for season in list(X['Season'].unique()):\n",
    "            \n",
    "            # add season to scores dictionary\n",
    "            if season not in scores:\n",
    "                scores[season] = []\n",
    "                \n",
    "            # split into train and validation sets\n",
    "            X_train = X[X['Season'] != season].drop(columns = ['Season'])\n",
    "            X_val = X[X['Season'] == season].drop(columns = ['Season'])\n",
    "            y_train = y[X_train.index]\n",
    "            y_val = y[X_val.index]\n",
    "            \n",
    "            # fit XGBoost model\n",
    "            xgb_model = XGBRegressor(**xgb_params).fit(X_train, y_train)\n",
    "            \n",
    "            # predict win probabilities\n",
    "            predictions = xgb_model.predict(X_val)\n",
    "            \n",
    "            # calculate log loss and store score\n",
    "            val_score = mean_squared_error(y_val, predictions)\n",
    "            scores[season].append(val_score)\n",
    "            \n",
    "        # retrain model on full dataset for feature importances\n",
    "        xgb_model = XGBRegressor(**xgb_params).fit(X.drop(columns = ['Season']), y)\n",
    "        \n",
    "        # store model details\n",
    "        model_coefs.append(xgb_params)\n",
    "        models.append(xgb_model)\n",
    "        \n",
    "    # return dataframe of results\n",
    "    return pd.DataFrame({'Type': ['xgb' for i in range(len(models))],\n",
    "                         'Num_Features': ['All' for i in range(len(models))],\n",
    "                         'Features': ['All' for i in range(len(models))],\n",
    "                         'Model': models,\n",
    "                         'Model_Coef': model_coefs,\n",
    "                         '2008_Score': scores[2008],\n",
    "                         '2009_Score': scores[2009],\n",
    "                         '2010_Score': scores[2010],\n",
    "                         '2011_Score': scores[2011],\n",
    "                         '2012_Score': scores[2012],\n",
    "                         '2013_Score': scores[2013],\n",
    "                         '2014_Score': scores[2014],\n",
    "                         '2015_Score': scores[2015],\n",
    "                         '2016_Score': scores[2016],\n",
    "                         '2017_Score': scores[2017],\n",
    "                         '2018_Score': scores[2018],\n",
    "                         '2019_Score': scores[2019]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [06:41<00:00, 20.06s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [13:11<00:00, 15.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# train the models\n",
    "#lm_results = train_linear_regression()\n",
    "rf_results = train_random_forest()\n",
    "xgb_results = train_xgboost()\n",
    "final_results = pd.concat([prev_results, rf_results, xgb_results], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentiles of scores in relation to other models\n",
    "score_cols = []\n",
    "for col in final_results.columns:\n",
    "    if col.endswith(\"Score\"):\n",
    "        score_cols.append(col)\n",
    "\n",
    "# calculate average score and average percentile\n",
    "final_results['Avg_Score'] = final_results[score_cols].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show feature importances of given model by results row index\n",
    "def features(row_index):\n",
    "    model = final_results.loc[row_index, 'Model']\n",
    "    \n",
    "    # if model is logistic regression, return coefficients\n",
    "    if final_results.loc[row_index, 'Type'] == 'log':\n",
    "        model_features = list(final_results.loc[row_index, 'Features'])\n",
    "        sign_list = []\n",
    "        coef_list = []\n",
    "        for i in range(len(model_features)):\n",
    "            coef = round(model.coef_[i], 6)\n",
    "            coef_list.append(coef)\n",
    "            if coef > 0:\n",
    "                sign_list.append('+')\n",
    "            else:\n",
    "                sign_list.append('-')\n",
    "        \n",
    "        return_df =  pd.DataFrame({'Feature': model_features,\n",
    "                             'Sign': sign_list,\n",
    "                            'Coefficient': coef_list})\n",
    "        return return_df.reindex(return_df['Coefficient'].abs().sort_values(ascending = False).index)\n",
    "        \n",
    "    # if model is random forest or XGBoost, return feature importance plot\n",
    "    else:\n",
    "        feat_importances = pd.Series(model.feature_importances_, index = X.drop(columns = ['Season']).columns)\n",
    "        return feat_importances.nlargest(15).plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show params of given model by results row index\n",
    "def params(row_index):\n",
    "    return final_results.loc[row_index, 'Model_Coef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Avg_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.030918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.030927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type  Avg_Score\n",
       "732  xgb   0.030783\n",
       "758  xgb   0.030783\n",
       "738  xgb   0.030783\n",
       "740  xgb   0.030783\n",
       "720  xgb   0.030783\n",
       "745  xgb   0.030783\n",
       "649  xgb   0.030814\n",
       "405  xgb   0.030814\n",
       "533  xgb   0.030814\n",
       "733  xgb   0.030814\n",
       "588  xgb   0.030814\n",
       "663  xgb   0.030814\n",
       "648  xgb   0.030814\n",
       "633  xgb   0.030814\n",
       "462   rf   0.030830\n",
       "471   rf   0.030880\n",
       "338   rf   0.030885\n",
       "452   rf   0.030885\n",
       "10    rf   0.030885\n",
       "183   rf   0.030885\n",
       "485   rf   0.030889\n",
       "319   rf   0.030890\n",
       "479   rf   0.030895\n",
       "703   rf   0.030904\n",
       "187   rf   0.030905\n",
       "44    rf   0.030906\n",
       "372  xgb   0.030918\n",
       "678  xgb   0.030918\n",
       "532  xgb   0.030918\n",
       "385  xgb   0.030918\n",
       "562  xgb   0.030918\n",
       "299  xgb   0.030918\n",
       "236  xgb   0.030918\n",
       "262  xgb   0.030918\n",
       "440  xgb   0.030918\n",
       "630  xgb   0.030918\n",
       "662  xgb   0.030918\n",
       "536  xgb   0.030918\n",
       "560  xgb   0.030918\n",
       "128  xgb   0.030918\n",
       "367  xgb   0.030918\n",
       "613  xgb   0.030918\n",
       "431  xgb   0.030918\n",
       "571  xgb   0.030918\n",
       "710   rf   0.030923\n",
       "49    rf   0.030923\n",
       "24    rf   0.030927\n",
       "467   rf   0.030927\n",
       "490   rf   0.030927\n",
       "185   rf   0.030927"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results\n",
    "pd.set_option('display.max_rows', 50)\n",
    "final_results[['Type', 'Avg_Score']].sort_values(by = ['Avg_Score'], ascending = True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features(732)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor(max_depth=5, max_features=12, min_samples_leaf=0.01,\\n                      n_estimators=1000, random_state=0)'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results.loc[462, 'Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason this model didn't save\n",
    "rf_model = RandomForestRegressor(n_estimators = 500,\n",
    "                                         max_depth = 5,\n",
    "                                         min_samples_leaf = 0.01,\n",
    "                                         max_features = 12,\n",
    "                                         random_state = 0).fit(X.drop(columns = ['Season']), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(rf_model.feature_importances_, index = X.drop(columns = ['Season']).columns)\n",
    "feat_importances.nlargest(15).plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[['Type', 'Num_Features', 'Features', 'Model', 'Model_Coef', '2008_Score',\n",
    "               '2009_Score', '2010_Score', '2011_Score', '2012_Score', '2013_Score',\n",
    "               '2014_Score', '2015_Score', '2016_Score', '2017_Score', '2018_Score',\n",
    "               '2019_Score']].to_csv('mydata/training_results_spread.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_results.loc[732, 'Model'], open('models/MSpreadXGB.sav', 'wb'))\n",
    "pickle.dump(rf_model, open('models/MSpreadRF.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
